{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要事先通过 pip3 install jieba\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba分词的三种分词模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['精确', '模式', '，', '试图', '将', '句子', '最', '精确', '地', '切开', '，', '适合', '文本', '分析', '；', '\\n', '全', '模式', '，', '把', '句子', '中', '所有', '的', '可以', '成词', '的', '词语', '都', '扫描', '出来', ',', ' ', '速度', '非常', '快', '，', '但是', '不能', '解决', '歧义', '；', '\\n', '搜索引擎', '模式', '，', '在', '精确', '模式', '的', '基础', '上', '，', '对长', '词', '再次', '切分', '，', '提高', '召回', '率', '，', '适合', '用于', '搜索引擎', '分词', '。']\n"
     ]
    }
   ],
   "source": [
    "## 精确模式:试图将句子最精确地切开，适合文本分析，不会有重复描述部分。\n",
    "seg_list = jieba.cut(text, cut_all=False)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['精确', '模式', '', '', '试图', '将', '句子', '最', '精确', '地', '切开', '', '', '适合', '文本', '本分', '分析', '', '\\n', '全', '模式', '', '', '把', '句子', '中所', '所有', '的', '可以', '成', '词', '的', '词语', '都', '扫描', '描出', '描出来', '出来', '', '', '', '速度', '非常', '快', '', '', '但是', '不能', '能解', '解决', '歧义', '', '\\n', '搜索', '搜索引擎', '索引', '引擎', '模式', '', '', '在', '精确', '模式', '的', '基础', '上', '', '', '对', '长', '词', '再次', '切分', '', '', '提高', '召回', '率', '', '', '适合', '合用', '用于', '搜索', '搜索引擎', '索引', '引擎', '分词', '', '']\n"
     ]
    }
   ],
   "source": [
    "## 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义:\n",
    "seg_list = jieba.cut(text, cut_all=True)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['精确', '模式', '，', '试图', '将', '句子', '最', '精确', '地', '切开', '，', '适合', '文本', '分析', '；', '\\n', '全', '模式', '，', '把', '句子', '中', '所有', '的', '可以', '成词', '的', '词语', '都', '扫描', '出来', ',', ' ', '速度', '非常', '快', '，', '但是', '不能', '解决', '歧义', '；', '\\n', '搜索', '索引', '引擎', '搜索引擎', '模式', '，', '在', '精确', '模式', '的', '基础', '上', '，', '对长', '词', '再次', '切分', '，', '提高', '召回', '率', '，', '适合', '用于', '搜索', '索引', '引擎', '搜索引擎', '分词', '。']\n"
     ]
    }
   ],
   "source": [
    "## 搜索引擎模式：将长词部分做二次分割处理\n",
    "seg_list = jieba.cut_for_search(text)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba分词的词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba import posseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_list = posseg.cut(text)\n",
    "#print(list(seg_list))\n",
    "\n",
    "#for word, pos in seg_list:\n",
    "#    print(word, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例：统计文本中的词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# collections 包含了很多Python的奇妙的类，Counter是一个计数器，可以统计元素出现的个数\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_page(url):\n",
    "    headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko\"}\n",
    "    html = requests.get(url, headers = headers).content\n",
    "    #print(html)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    content_list = soup.find_all(\"p\")\n",
    "    #for content in content_list:\n",
    "    #    content.get_text()\n",
    "    # 取出每个结点的内容并处理为字符串\n",
    "    text = \" \".join([content.get_text() for content in content_list])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deal_text(text):\n",
    "    # 1. 分词：全模式分词，并获取单词长度大于等于2的单词 的列表\n",
    "    seg_list = [word for word in jieba.cut(text, cut_all=True) if len(word) >= 2]\n",
    "    #print(len(seg_list))\n",
    "    \n",
    "    # 2. 获取停用词列表, Python3 里的open 打开文件后，可以指定按encoding编码处理文本\n",
    "    stopword_list = [i.strip() for i in open(\"四川大学机器智能实验室停用词库.txt\", \"r\", encoding='utf-8')]\n",
    "    \n",
    "    # 3. 去除停用词\n",
    "    filtered_list = [seg for seg in seg_list if seg not in stopword_list]\n",
    "    #print(len(filtered_list))\n",
    "    \n",
    "    # 4. 统计词频\n",
    "    \n",
    "    # Counter 返回的是一个类字典对象\n",
    "    dict_obj = Counter(filtered_list)\n",
    "    #print(dict_obj)\n",
    "    \n",
    "    # 字典对象有个方法叫 most_common(20), 返回类字典对象的前20个元素\n",
    "    word_list = dict_obj.most_common(20)\n",
    "    \n",
    "    for index, word in enumerate(word_list):\n",
    "        print(index, word[0], word[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 发展 134\n",
      "1 改革 85\n",
      "2 经济 71\n",
      "3 推进 66\n",
      "4 建设 59\n",
      "5 社会 49\n",
      "6 人民 47\n",
      "7 企业 46\n",
      "8 加强 46\n",
      "9 政策 46\n",
      "10 政府 44\n",
      "11 全面 44\n",
      "12 推动 42\n",
      "13 创新 41\n",
      "14 加快 41\n",
      "15 服务 38\n",
      "16 中国 37\n",
      "17 完善 36\n",
      "18 工作 35\n",
      "19 国家 35\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.gov.cn/premier/2017-03/16/content_5177940.htm\"\n",
    "text = load_page(url)\n",
    "deal_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
