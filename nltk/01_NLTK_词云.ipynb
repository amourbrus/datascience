{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本处理+词云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import jieba\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "def send_request(url):\n",
    "    '''\n",
    "        抓取网页文本数据并返回\n",
    "    '''\n",
    "    headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.86 Safari/537.36\"}\n",
    "    # 发送url请求并获取响应文件\n",
    "    html = requests.get(url, headers = headers).content\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    # 解析出所有的p标签\n",
    "    content_list = soup.find_all('p')\n",
    "\n",
    "    text = ''\n",
    "    # 将p标签里的所有内容都保存到一个字符串里\n",
    "    for content in content_list:\n",
    "        text += content.get_text()\n",
    "        text += '\\n'\n",
    "\n",
    "    return text\n",
    "\n",
    "def deal_page(text):\n",
    "    '''\n",
    "        统计文本的词频\n",
    "    '''\n",
    "\n",
    "    # 利用jieba进行分词，返回所有分词后长度大于等于2 的词的列表\n",
    "    seg_list = [word for word in jieba.cut(text, cut_all=True) if len(word) >= 2]\n",
    "\n",
    "    # 处理词频统计\n",
    "    # nltk.FreqDist()接收一个列表，返回类字典对象\n",
    "    freq_dist = nltk.FreqDist(seg_list)\n",
    "\n",
    "    # most_common(10) ：获取词频统计排名最高的前10个\n",
    "    top_word = freq_dist.most_common(10)\n",
    "\n",
    "    print(\"统计高频词的排名：\")\n",
    "    for word, count in top_word:\n",
    "        print(word + \" : \" + str(count))\n",
    "\n",
    "    # return dict(top_word)\n",
    "    return freq_dist\n",
    "\n",
    "def word_could(freq_dist):\n",
    "    \"\"\"\n",
    "        绘制词云\n",
    "    \"\"\"\n",
    "    # 图片向量化\n",
    "    background_image = np.array(Image.open(\"./test.jpg\"))\n",
    "\n",
    "    # 设置词云属性\n",
    "    wc = WordCloud(font_path='C:\\Windows\\Fonts\\msyh.ttc',  # 设置微软雅黑字体\n",
    "                   #font_path=\"/Library/Fonts/Microsoft/Microsoft Yahei.ttf\",\n",
    "                   background_color=\"white\",  # 背景颜色\n",
    "                   max_words=200,  # 词云显示的最大词数\n",
    "                   mask=background_image,  # 设置背景图片\n",
    "                   max_font_size=100,  # 字体最大值\n",
    "                   #min_font_size=20,\n",
    "    )\n",
    "\n",
    "    # 获取词频数据，参数为类字典对象\n",
    "    wc.generate_from_frequencies(freq_dist)\n",
    "\n",
    "    # 获取背景图片的颜色\n",
    "    image_colors = ImageColorGenerator(background_image)\n",
    "\n",
    "    plt.figure(figsize=(14, 9), dpi=100)\n",
    "    plt.imshow(wc.recolor(color_func=image_colors))\n",
    "    # plt.imshow(wc)\n",
    "\n",
    "    # 不显示刻度\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # 保存词云\n",
    "    wc.to_file(\"word.png\")        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'http://www.gov.cn/premier/2017-03/16/content_5177940.htm'\n",
    "    text = send_request(url)\n",
    "    freq_dist = deal_page(text)\n",
    "    word_could(freq_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
