{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调出NLTK的下载器，可以下载需要的语料库和分词模型等...\n",
    "nltk.download()\n",
    "\n",
    "# 需要安装 - \n",
    "# Corpora ： brown、wordnet、stopwords\n",
    "# Models ： porter_test 、punkt、averaged_perceptron_tagger\n",
    "\n",
    "# 额外安装：\n",
    "# pip3 install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BROWN CORPUS\n",
      "\n",
      "A Standard Corpus of Present-Day Edited American\n",
      "English, for use with Digital Computers.\n",
      "\n",
      "by W. N. Francis and H. Kucera (1964)\n",
      "Department of Linguistics, Brown University\n",
      "Providence, Rhode Island, USA\n",
      "\n",
      "Revised 1971, Revised and Amplified 1979\n",
      "\n",
      "http://www.hit.uib.no/icame/brown/bcm.html\n",
      "\n",
      "Distributed with the permission of the copyright holder,\n",
      "redistribution permitted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 语料库的信息简介\n",
    "print(brown.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "# 查看语料库里包含的分类\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57340\n",
      "1161192\n"
     ]
    }
   ],
   "source": [
    "# 查看包含的句子和单词的数量\n",
    "print(len(brown.sents()))\n",
    "print(len(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 英文分词 （punkt分词模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要处理的文本内容\n",
    "text = \"Python is a high-level programming language, and i like it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'a', 'high-level', 'programming', 'language', ',', 'and', 'i', 'like', 'it', '!']\n"
     ]
    }
   ],
   "source": [
    "# 使用nltk的分词工具 (需要实现安装punkt分词模型)\n",
    "# 分词结构是一个列表\n",
    "\n",
    "#print(text.split())\n",
    "seg_list = nltk.word_tokenize(text)\n",
    "print(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 中文分词 （jieba分词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"习近平在参加党的十九大贵州省代表团讨论时强调：全党全国各族人民万众一心，开拓进取，把新时代中国特色社会主义推向前进。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['习近平', '在', '参加', '党', '的', '十九', '九大', '贵州', '贵州省', '代表', '代表团', '讨论', '时', '强调', '', '', '全党', '全党全国', '全国', '各族', '各族人民', '族人', '人民', '万众', '万众一心', '一心', '', '', '开拓', '开拓进取', '进取', '', '', '把', '新', '时代', '中国', '国特', '特色', '社会', '社会主义', '会主', '主义', '推向', '向前', '前进', '', '']\n"
     ]
    }
   ],
   "source": [
    "# 使用全模式的 结巴分词 : 把所有可能称为词语的结果罗列出来 （ 一般用在文本内容统计：词频）\n",
    "seg_list = jieba.cut(text, cut_all=True)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['习近平', '在', '参加', '党', '的', '十九', '大', '贵州省', '代表团', '讨论', '时', '强调', '：', '全党全国', '各族人民', '万众一心', '，', '开拓进取', '，', '把', '新', '时代', '中国', '特色', '社会主义', '推向', '前进', '。']\n"
     ]
    }
   ],
   "source": [
    "# 使用精确模式 的结巴分词：尽可能的按中文语义进行分词 (文本分析)\n",
    "seg_list = jieba.cut(text, cut_all=False)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.处理词性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 词干提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. PorterStemmer （早期的一款词干提取算法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 波特　词干提取算法\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建一个波特词干提取对象\n",
    "porter_steammer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look\n",
      "look\n",
      "look\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "# look 、looked、looking，词干都是look\n",
    "print(porter_steammer.stem(\"look\"))\n",
    "print(porter_steammer.stem(\"looked\"))\n",
    "print(porter_steammer.stem(\"looking\"))\n",
    "\n",
    "print(porter_steammer.stem(\"run\"))\n",
    "print(porter_steammer.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SnowballStemmer  (可以支持多个语言，并兼容porter）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look\n",
      "look\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "print(snowball_stemmer.stem(\"look\"))\n",
    "print(snowball_stemmer.stem(\"looked\"))\n",
    "print(snowball_stemmer.stem(\"looking\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. LancasterStemmer （速度较快，常用于英文词干提取）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lancaster_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look\n",
      "look\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "print(lancaster_stemmer.stem(\"look\"))\n",
    "print(lancaster_stemmer.stem(\"looked\"))\n",
    "print(lancaster_stemmer.stem(\"looking\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 词形归并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 词形归并：将单词的各种词形归并为统一的词形\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "cat\n",
      "are\n",
      "went\n"
     ]
    }
   ],
   "source": [
    "# 默认全部按 名词 做词形归并\n",
    "print(lemmatizer.lemmatize(\"dogs\"))\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"are\"))\n",
    "print(lemmatizer.lemmatize(\"went\"))  # went 有可能是动词go，有可能是名词文特"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "# 通过pos参数，指定词性 进行词形归并\n",
    "print(lemmatizer.lemmatize(\"are\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"went\", pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 词性标注 (分词的同时，标注单词的词性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要实现安装 averaged_perceptron_tagger\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要处理的文本内容\n",
    "text = \"Python is a high-level programming language, and i like it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'a', 'high-level', 'programming', 'language', ',', 'and', 'i', 'like', 'it', '!']\n"
     ]
    }
   ],
   "source": [
    "#1. 先分词\n",
    "seg_list = nltk.word_tokenize(text)\n",
    "print(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), ('programming', 'NN'), ('language', 'NN'), (',', ','), ('and', 'CC'), ('i', 'VBP'), ('like', 'IN'), ('it', 'PRP'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "#2. 词性标注，参数是分词后的列表\n",
    "# 返回包含所有单词和词性的列表\n",
    "pos_list = nltk.pos_tag(seg_list)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给每一个字符做词性标注：整句模式\n",
    "#print(nltk.pos_tag_sents(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. 去停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 停用词：文本里经常出现，但是又没有特殊的含义的词语。为了节省空间提高统计分析速度，会去除停用词（过滤）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入nltk的停用词语料库，需要事先下载安装 stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要处理的文本内容\n",
    "text = \"Python is a high-level programming language, and i like it!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'a', 'high-level', 'programming', 'language', ',', 'and', 'i', 'like', 'it', '!']\n"
     ]
    }
   ],
   "source": [
    "# 先分词\n",
    "seg_list = nltk.word_tokenize(text)\n",
    "print(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'high-level', 'programming', 'language', ',', 'like', '!']\n"
     ]
    }
   ],
   "source": [
    "# 去除停用词后的列表\n",
    "filtered_list = [seg for seg in seg_list if seg not in stopwords.words(\"english\")]\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 常用的文本预处理流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分词\n",
    "import nltk\n",
    "# 词形归并\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# 去停用词\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要处理的文本\n",
    "# 生活就像一盒巧克力，你永远不知道下一个会拿到什么。\n",
    "text = \"Life was like a box of chocolates, you never know what you\\' re gonna get.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life', 'was', 'like', 'a', 'box', 'of', 'chocolates', ',', 'you', 'never', 'know', 'what', 'you', \"'\", 're', 'gon', 'na', 'get', '.']\n"
     ]
    }
   ],
   "source": [
    "## 1. 分词处理，返回分词后的单词列表\n",
    "seg_list = nltk.word_tokenize(text)\n",
    "print(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life', 'wa', 'like', 'a', 'box', 'of', 'chocolate', ',', 'you', 'never', 'know', 'what', 'you', \"'\", 're', 'gon', 'na', 'get', '.']\n"
     ]
    }
   ],
   "source": [
    "## 2. 词形归并\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "word_list = [lemmatizer.lemmatize(seg) for seg in seg_list]\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life', 'wa', 'like', 'box', 'chocolate', ',', 'never', 'know', \"'\", 'gon', 'na', 'get', '.']\n"
     ]
    }
   ],
   "source": [
    "### 3. 去停用词\n",
    "filtered_list = [word for word in word_list if word not in stopwords.words(\"english\")]\n",
    "#print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文本内容: Life was like a box of chocolates, you never know what you' re gonna get.\n",
      "处理后的文本：Life wa like box chocolate , never know ' gon na get .\n"
     ]
    }
   ],
   "source": [
    "### 4. 文本对比\n",
    "print(\"原文本内容: {}\".format(text))\n",
    "print(\"预处理后的文本：{}\".format(\" \".join(filtered_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
